# ML Prediction Pipeline â€” Timeâ€‘Series Regression (CNN + GRU)

Professional, endâ€‘toâ€‘end pipeline for **timeâ€‘series / tabular regression**:
- **Model**: CNN â†’ GRU â†’ Dense (Keras/TensorFlow)
- **Data processing**: `StandardScaler` for inputs/target, optional **Oneâ€‘Hot** for categoricals
- **Training artifacts**: model (`.keras`), scalers/encoders (`.gz`), `feature_config.json`
- **Evaluation**: MAE/RMSE/RÂ², learning curves, interactive HTML plots
- **UX**: clean notebooks, repo structure ready for CI/packaging

> Fits portfolio useâ€‘cases and predictive maintenance demos. Works on CPU/GPU.

---

## ğŸ“¦ Repository structure

```
.
â”œâ”€ notebooks/
â”‚  â””â”€ 01_train.ipynb           # Training notebook (endâ€‘toâ€‘end)
â”œâ”€ src/mlpp/                    # (slot for shared code if needed later)
â”œâ”€ TRAIN/                       # Put your training CSVs here (examples included)
â”œâ”€ TEST/                        # Put your test CSVs here (examples included)
â”œâ”€ OUTPUTS/                     # Training artifacts & plots (gitâ€‘ignored)
â”œâ”€ scripts/
â”‚  â””â”€ quickstart.sh             # (optional) oneâ€‘command setup & run
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â”œâ”€ LICENSE
â””â”€ README.md
```

> If you keep a separate prediction workflow (GUI/CLI), add `notebooks/02_predict.ipynb` or `scripts/predict.py` and place shared helpers in `src/mlpp/`.

---

## ğŸ§  Task & data schema

**Task:** univariate regression on timeâ€‘ordered data (predict a continuous `target`).

**Default input columns:**
```
feature_01 .. feature_12, comp_active
```
**Target column:**
```
target
```
You can change column names inside the notebook (section **Konfiguracja**).

> CSV delimiter is autoâ€‘detected; a robust fallback to `;` and to default `,` is included.

---

## ğŸš€ Quickstart

### 1) Environment
```bash
python -m venv .venv && source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
```

### 2) Data
- Put your CSVs into **TRAIN/** and **TEST/**.  
- See examples in `TRAIN/example_train.csv` and `TEST/example_test.csv` for the expected headers.

### 3) Run
Open the notebook and run all cells:
```bash
jupyter lab   # or: jupyter notebook / VS Code
```
Artifacts (models, scalers, encoders, plots) land under **OUTPUTS/** in a timestamped subfolder.

---

## ğŸ“Š Outputs
- `OUTPUTS/<timestamp>/best_model.keras` â€” best checkpoint by `val_loss`
- `OUTPUTS/<timestamp>/scaler.gz`, `output_scaler.gz`, `encoders.gz` â€” preprocessing
- `OUTPUTS/<timestamp>/feature_config.json` â€” persisted input/output columns
- `OUTPUTS/<timestamp>/*.png` â€” loss/MAE curves
- `OUTPUTS/<timestamp>/*.html` â€” interactive prediction diff plots
- `OUTPUTS/<timestamp>/test_metrics.csv` â€” perâ€‘file MSE/RMSE/MAE/RÂ²

---

## ğŸ› ï¸ Tech stack
- TensorFlow / Keras (2.x), NumPy, Pandas
- scikitâ€‘learn (StandardScaler, OneHotEncoder)
- Matplotlib & Plotly (interactive HTML)
- Joblib for artifact persistence
- Jupyter environment

---

## ğŸ”„ Reproducibility & quality
- Deterministic seeds for NumPy/TensorFlow
- EarlyStopping + ReduceLROnPlateau + ModelCheckpoint
- Schema validation (`STRICT_SCHEMA`) with a tolerant fallback
- Robust CSV delimiter detection

---

## ğŸ—ºï¸ Roadmap (suggested)
- [ ] Notebook `02_predict.ipynb` for inference from saved artifacts
- [ ] `scripts/predict.py` (CLI): `--artifacts`, `--csv`, `--out`
- [ ] `src/mlpp/` helpers for shared preprocessing & plotting
- [ ] GitHub Actions: smokeâ€‘test `pip install` + notebook import
- [ ] MLflow experiment tracking (optional)

---

## ğŸ“„ License
Released under the **MIT License** (see [LICENSE](LICENSE)).

---

## ğŸ¤ Acknowledgements
Built as a clean, portfolioâ€‘friendly baseline for regression on timeâ€‘ordered industrial data.
